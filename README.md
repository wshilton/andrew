# socialregulator

The aim of this work is to develop a social and emotional regulation network using a prototype platform for detecting, tracking, and classifying (DTC) fully context-based social data. The platform is envisioned to provide a unified, multi-domain sensor-based API, which integrates sensor inputs into social primitives using specially refined and filtered data streams with both integrated and specialized neural networks across text, image and audio domains, for the social regulation framework.

Phase One: Real-time DTC is expected for the hardware, in which a databse of social primitives is populated.

Phase Two: Real-time integration -- a real-time socioemotional response to the social primitives database -- will follow maturation of an appropriate training dataset.

Phase Three: Design, development, and testing of a regulation mechanism for the socioemotional response for application purposes. In the most general sense, this, say, social regulation network, must identify at least one homotopy (discretized at an appropriate resolution) for the human identity under consideration. The homotopy describes the current psychological state for the human identity, a future psychological state, and the sequence of intermediate states together with a description of transforms for the state maps that specify what social and emotional input from the artificial intelligence is needed in order to transform between two computed states. Various feedback mechanisms for refinement of the predictions would also be implemented as needed dependent upon measured outcomes as obsered in the social primitives database.

Phase Four: Generalize the regulation mechanism to include group dynamics, so that a collection of homotopies is generated for a group of individuals. Predicted input from the in-group members would be considered as part of the mapping transforms such that the progression among states is highly interlinked, with, of course, optimal paths taken as the solution.

Concerning the Phase One platform, a catalog of unique facial identities will be constructed, following some elementary post-processing (gain normalization, etc), from various Haar cascade filters and linear synthetic discriminants applied to optical input. Use of a uniform planar microwave array is envisioned for motion detection, which aids time-series identity management -- both alerting process managers to initiate finer optical-based facial recognition and aiding optical tracking algorithms for moving-target processing. Parallel infrared processing on regions with active identities will aid the optical data for purposes of generating a classification of emotional states for the identity. Likewise, acoustic data from a beamsteered uniform circular and uniform planar acoustic array may be integrated with the optical and infrared data for acquiring an acoustic signal that identifies unique (via multi-focal beamsteering) vocal utterances, along with, perhaps, facilities for validating and verifying the acoustic signature for purposes of identity management. Angle-of-arrival capabilities in the uniform cicruclar array will also aid in scheduling based on the detection of certain acoustic signals. Spatial awareness is gathered from an inertial sensor.

Once all of the relevant social primitives have been constructed for all signals from a given context, the platform will have established a condition of social awareness for a small time interval described by a collection of human identities, emotional states, utterances, and body language symbols. This data is to be integrated in later project phases with some (possibly large) collection of historical moments using cross-domain neural networks for purposes of generating socially relevant responses to the moment.
