{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c143763",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mediapipe import solutions\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def draw_face_landmarks_on_image(rgb_image, detection_result):\n",
    "    face_landmarks_list = detection_result.face_landmarks\n",
    "    annotated_image = np.copy(rgb_image)\n",
    "\n",
    "    # Loop through the detected faces to visualize.\n",
    "    for idx in range(len(face_landmarks_list)):\n",
    "        face_landmarks = face_landmarks_list[idx]\n",
    "\n",
    "        # Draw the face landmarks.\n",
    "        face_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "        face_landmarks_proto.landmark.extend([\n",
    "          landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in face_landmarks\n",
    "        ])\n",
    "\n",
    "        solutions.drawing_utils.draw_landmarks(\n",
    "            image=annotated_image,\n",
    "            landmark_list=face_landmarks_proto,\n",
    "            connections=mp.solutions.face_mesh.FACEMESH_TESSELATION,\n",
    "            landmark_drawing_spec=None,\n",
    "            connection_drawing_spec=mp.solutions.drawing_styles\n",
    "            .get_default_face_mesh_tesselation_style())\n",
    "        solutions.drawing_utils.draw_landmarks(\n",
    "            image=annotated_image,\n",
    "            landmark_list=face_landmarks_proto,\n",
    "            connections=mp.solutions.face_mesh.FACEMESH_CONTOURS,\n",
    "            landmark_drawing_spec=None,\n",
    "            connection_drawing_spec=mp.solutions.drawing_styles\n",
    "            .get_default_face_mesh_contours_style())\n",
    "        solutions.drawing_utils.draw_landmarks(\n",
    "            image=annotated_image,\n",
    "            landmark_list=face_landmarks_proto,\n",
    "            connections=mp.solutions.face_mesh.FACEMESH_IRISES,\n",
    "              landmark_drawing_spec=None,\n",
    "              connection_drawing_spec=mp.solutions.drawing_styles\n",
    "              .get_default_face_mesh_iris_connections_style())\n",
    "\n",
    "    return annotated_image\n",
    "\n",
    "def plot_face_blendshapes_bar_graph(face_blendshapes):\n",
    "    # Extract the face blendshapes category names and scores.\n",
    "    face_blendshapes_names = [face_blendshapes_category.category_name for face_blendshapes_category in face_blendshapes]\n",
    "    face_blendshapes_scores = [face_blendshapes_category.score for face_blendshapes_category in face_blendshapes]\n",
    "    # The blendshapes are ordered in decreasing score value.\n",
    "    face_blendshapes_ranks = range(len(face_blendshapes_names))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "    bar = ax.barh(face_blendshapes_ranks, face_blendshapes_scores, label=[str(x) for x in face_blendshapes_ranks])\n",
    "    ax.set_yticks(face_blendshapes_ranks, face_blendshapes_names)\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    # Label each bar with values\n",
    "    for score, patch in zip(face_blendshapes_scores, bar.patches):\n",
    "        plt.text(patch.get_x() + patch.get_width(), patch.get_y(), f\"{score:.4f}\", va=\"top\")\n",
    "\n",
    "    ax.set_xlabel('Score')\n",
    "    ax.set_title(\"Face Blendshapes\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def draw_pose_landmarks_on_image(rgb_image, detection_result):\n",
    "    pose_landmarks_list = detection_result.pose_landmarks\n",
    "    annotated_image = np.copy(rgb_image)\n",
    "\n",
    "    # Loop through the detected poses to visualize.\n",
    "    for idx in range(len(pose_landmarks_list)):\n",
    "        pose_landmarks = pose_landmarks_list[idx]\n",
    "\n",
    "        # Draw the pose landmarks.\n",
    "        pose_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "        pose_landmarks_proto.landmark.extend([\n",
    "          landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in pose_landmarks\n",
    "        ])\n",
    "        solutions.drawing_utils.draw_landmarks(\n",
    "          annotated_image,\n",
    "          pose_landmarks_proto,\n",
    "          solutions.pose.POSE_CONNECTIONS,\n",
    "          solutions.drawing_styles.get_default_pose_landmarks_style())\n",
    "    return annotated_image\n",
    "\n",
    "MARGIN = 10  # pixels\n",
    "FONT_SIZE = 1\n",
    "FONT_THICKNESS = 1\n",
    "HANDEDNESS_TEXT_COLOR = (88, 205, 54) # vibrant green\n",
    "\n",
    "def draw_hand_landmarks_on_image(rgb_image, detection_result):\n",
    "    hand_landmarks_list = detection_result.hand_landmarks\n",
    "    handedness_list = detection_result.handedness\n",
    "    annotated_image = np.copy(rgb_image)\n",
    "\n",
    "    # Loop through the detected hands to visualize.\n",
    "    for idx in range(len(hand_landmarks_list)):\n",
    "        hand_landmarks = hand_landmarks_list[idx]\n",
    "        handedness = handedness_list[idx]\n",
    "\n",
    "        # Draw the hand landmarks.\n",
    "        hand_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "        hand_landmarks_proto.landmark.extend([\n",
    "          landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in hand_landmarks\n",
    "        ])\n",
    "        solutions.drawing_utils.draw_landmarks(\n",
    "          annotated_image,\n",
    "          hand_landmarks_proto,\n",
    "          solutions.hands.HAND_CONNECTIONS,\n",
    "          solutions.drawing_styles.get_default_hand_landmarks_style(),\n",
    "          solutions.drawing_styles.get_default_hand_connections_style())\n",
    "\n",
    "        # Get the top left corner of the detected hand's bounding box.\n",
    "        height, width, _ = annotated_image.shape\n",
    "        x_coordinates = [landmark.x for landmark in hand_landmarks]\n",
    "        y_coordinates = [landmark.y for landmark in hand_landmarks]\n",
    "        text_x = int(min(x_coordinates) * width)\n",
    "        text_y = int(min(y_coordinates) * height) - MARGIN\n",
    "\n",
    "        # Draw handedness (left or right hand) on the image.\n",
    "        cv2.putText(annotated_image, f\"{handedness[0].category_name}\",\n",
    "                    (text_x, text_y), cv2.FONT_HERSHEY_DUPLEX,\n",
    "                    FONT_SIZE, HANDEDNESS_TEXT_COLOR, FONT_THICKNESS, cv2.LINE_AA)\n",
    "\n",
    "    return annotated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c4d1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: Import the necessary modules.\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "vid = cv2.VideoCapture(0)\n",
    "codec = cv2.VideoWriter_fourcc('M','J','P','G')\n",
    "vid.set(6, codec)\n",
    "vid.set(5, 30)\n",
    "vid.set(3, 1280)\n",
    "vid.set(4, 720)\n",
    "out = cv2.VideoWriter('output.avi',codec, 10, (1280,720))\n",
    "\n",
    "# STEP 2: Create an landmarker objects.\n",
    "BaseOptions = mp.tasks.BaseOptions\n",
    "VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "\n",
    "FaceLandmarker = mp.tasks.vision.FaceLandmarker\n",
    "FaceLandmarkerOptions = mp.tasks.vision.FaceLandmarkerOptions\n",
    "FaceLandmarkerResult = mp.tasks.vision.FaceLandmarkerResult\n",
    "\n",
    "PoseLandmarker = mp.tasks.vision.PoseLandmarker\n",
    "PoseLandmarkerOptions = mp.tasks.vision.PoseLandmarkerOptions\n",
    "PoseLandmarkerResult = mp.tasks.vision.PoseLandmarkerResult\n",
    "\n",
    "HandLandmarker = mp.tasks.vision.HandLandmarker\n",
    "HandLandmarkerOptions = mp.tasks.vision.HandLandmarkerOptions\n",
    "HandLandmarkerResult = mp.tasks.vision.HandLandmarkerResult\n",
    "\n",
    "class LandmarkerBuffer():\n",
    "    \n",
    "    faces = FaceLandmarkerResult('','','')\n",
    "    poses = PoseLandmarkerResult('','')\n",
    "    hands = HandLandmarkerResult('','','')\n",
    "\n",
    "    def add_faces(self, result: FaceLandmarkerResult):\n",
    "        self.faces = result\n",
    "    \n",
    "    def add_poses(self, result: PoseLandmarkerResult):\n",
    "        self.poses = result\n",
    "        \n",
    "    def add_hands(self, result: HandLandmarkerResult):\n",
    "        self.hands = result\n",
    "        \n",
    "    def process(self, image: mp.Image):\n",
    "        annotated_image = draw_face_landmarks_on_image(image.numpy_view(), self.faces)\n",
    "        annotated_image = draw_pose_landmarks_on_image(annotated_image, self.poses)\n",
    "        annotated_image = draw_hand_landmarks_on_image(annotated_image, self.hands)\n",
    "        return annotated_image\n",
    "    \n",
    "landmarkbuffer = LandmarkerBuffer()\n",
    "\n",
    "# Create a face landmarker instance with the live stream mode:\n",
    "def update_face_buffer(result: FaceLandmarkerResult, output_image: mp.Image, timestamp_ms: int):\n",
    "    landmarkbuffer.add_faces(result)\n",
    "    \n",
    "def update_pose_buffer(result: PoseLandmarkerResult, output_image: mp.Image, timestamp_ms: int):\n",
    "    landmarkbuffer.add_poses(result)\n",
    "    \n",
    "def update_hand_buffer(result: HandLandmarkerResult, output_image: mp.Image, timestamp_ms: int):\n",
    "    landmarkbuffer.add_hands(result)\n",
    "\n",
    "face_options = FaceLandmarkerOptions(\n",
    "    base_options=BaseOptions(model_asset_path='face_landmarker.task'),\n",
    "    running_mode=VisionRunningMode.LIVE_STREAM,\n",
    "    result_callback=update_face_buffer)\n",
    "\n",
    "pose_options = PoseLandmarkerOptions(\n",
    "    base_options=BaseOptions(model_asset_path='pose_landmarker_lite.task'),\n",
    "    running_mode=VisionRunningMode.LIVE_STREAM,\n",
    "    result_callback=update_pose_buffer)\n",
    "\n",
    "hand_options = HandLandmarkerOptions(\n",
    "    base_options=BaseOptions(model_asset_path='hand_landmarker.task'),\n",
    "    running_mode=VisionRunningMode.LIVE_STREAM,\n",
    "    result_callback=update_hand_buffer)\n",
    "\n",
    "with FaceLandmarker.create_from_options(face_options) as facelandmarker:\n",
    "    with PoseLandmarker.create_from_options(pose_options) as poselandmarker:\n",
    "        with HandLandmarker.create_from_options(hand_options) as handlandmarker:\n",
    "            while (vid.isOpened()):\n",
    "                ret, frame = vid.read()\n",
    "                frame_timestamp_ms = round(time.time()*1000)\n",
    "                # STEP 3: Load the input image.\n",
    "                image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame)\n",
    "\n",
    "                # STEP 4: Detect face landmarks from the live stream.\n",
    "                facelandmarker.detect_async(image, frame_timestamp_ms)\n",
    "                poselandmarker.detect_async(image, frame_timestamp_ms)\n",
    "                handlandmarker.detect_async(image, frame_timestamp_ms)\n",
    "\n",
    "                #Display frame\n",
    "                annotated_image = landmarkbuffer.process(image)\n",
    "                cv2.imshow(\"Face, pose, and hand landmarks\", annotated_image)\n",
    "                out.write(annotated_image)\n",
    "                \n",
    "                if cv2.waitKey(1) & 0xFF==ord('q'): # quit when 'q' is pressed\n",
    "                    vid.release()\n",
    "                    break\n",
    "\n",
    "out.release()\n",
    "cv2.destroyWindow(\"Face, pose, and hand landmarks\") \n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416942f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_andrew",
   "language": "python",
   "name": "project_andrew"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
